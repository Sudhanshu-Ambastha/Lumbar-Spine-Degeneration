{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Import necessary libraries\nimport os\nimport numpy as np\nimport pandas as pd\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-30T12:05:43.342649Z","iopub.execute_input":"2024-05-30T12:05:43.343117Z"}}},{"cell_type":"raw","source":"print(\"hello\")","metadata":{}},{"cell_type":"code","source":"# Load VGG16 model (pre-trained on ImageNet)\nbase_model = VGG16(weights=\"imagenet\", include_top=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:14:09.354050Z","iopub.execute_input":"2024-05-30T12:14:09.355320Z","iopub.status.idle":"2024-05-30T12:14:10.457057Z","shell.execute_reply.started":"2024-05-30T12:14:09.355266Z","shell.execute_reply":"2024-05-30T12:14:10.455546Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract features from images\ndef extract_features(image_path):\n    img = load_img(image_path, target_size=(224, 224))\n    img_array = img_to_array(img)\n    img_array = np.expand_dims(img_array, axis=0)\n    features = base_model.predict(img_array)\n    return features.flatten()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:14:20.604383Z","iopub.execute_input":"2024-05-30T12:14:20.604860Z","iopub.status.idle":"2024-05-30T12:14:20.612235Z","shell.execute_reply.started":"2024-05-30T12:14:20.604823Z","shell.execute_reply":"2024-05-30T12:14:20.610828Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Prepare features (X) and labels (y)\nX = np.array([extract_features(os.path.join(image_folder, filename)) for filename in data[\"filename\"]])\ny = data[\"severity_scores\"]\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T12:14:25.994212Z","iopub.execute_input":"2024-05-30T12:14:25.995239Z","iopub.status.idle":"2024-05-30T12:14:26.293473Z","shell.execute_reply.started":"2024-05-30T12:14:25.995202Z","shell.execute_reply":"2024-05-30T12:14:26.291889Z"},"trusted":true},"execution_count":21,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prepare features (X) and labels (y)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([extract_features(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(image_folder, filename)) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseverity_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Split data into training and testing sets\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"],"ename":"NameError","evalue":"name 'data' is not defined","output_type":"error"}]}]}